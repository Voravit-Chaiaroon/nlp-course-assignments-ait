{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)\n",
    "\n",
    "In this lecture, we will explore the architecture of DistilBERT, its key components, and how it can be utilized for various natural language processing tasks. Additionally, we'll discuss its advantages, limitations, and provide hands-on examples to showcase its effectiveness.\n",
    "\n",
    "Reference : [The Theory](https://towardsdatascience.com/distillation-of-bert-like-models-the-code-73c31e8c2b0a) | [Code](https://towardsdatascience.com/distillation-of-bert-like-models-the-theory-32e19a02641f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.2.0', '4.47.1', '2.2.2+cu121')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install datasets --upgrade\n",
    "import datasets\n",
    "import transformers\n",
    "import torch\n",
    "datasets.__version__, transformers.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import random, math, time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# 1. Load the dataset\n",
    "dataset = load_dataset(\"ucberkeley-dlab/measuring-hate-speech\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# 2. Select unique comments\n",
    "df = df[[\"comment_id\", \"text\", \"hate_speech_score\"]]\n",
    "\n",
    "# 3. Create binary labels\n",
    "df[\"label\"] = (df[\"hate_speech_score\"] > 0.5).astype(int)\n",
    "data = df[[\"text\", \"label\"]]\n",
    "\n",
    "# 4. Split the data\n",
    "train_df, temp_df = train_test_split(data, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert to Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 94889\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 20333\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 20334\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"val\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fuck off you insufferable retarded faggot.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>White Small Little Invisible Clits Are A Disgr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@suddenlywestan Because you are a country of m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>This sub is full of grade A faggots  Comedy fu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Get rid of them and their anchor babies and gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>@KeGutta These niggas straight bitches</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Dwight Howard is a undercover Faggot, this guy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>@odysseuslahori @IqShoaib Hang till death all ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Saudi should attack Iran and see what happens ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "4   For starters bend over the one in pink and kic...      1\n",
       "7          Fuck off you insufferable retarded faggot.      1\n",
       "14  White Small Little Invisible Clits Are A Disgr...      1\n",
       "17  @suddenlywestan Because you are a country of m...      1\n",
       "18  This sub is full of grade A faggots  Comedy fu...      1\n",
       "24  Get rid of them and their anchor babies and gr...      1\n",
       "30             @KeGutta These niggas straight bitches      1\n",
       "37  Dwight Howard is a undercover Faggot, this guy...      1\n",
       "48  @odysseuslahori @IqShoaib Hang till death all ...      1\n",
       "50  Saudi should attack Iran and see what happens ...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['label'] == 1].head(10)\n",
    "#Sample hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'non-toxic': 0, 'toxic': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = ['non-toxic', 'toxic']\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'non-toxic', 1: 'toxic'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {i: v for v, i in label2id.items()}\n",
    "id2label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model & Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "num_labels = np.unique(raw_datasets['train']['label']).size\n",
    "num_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"figures/BERT_embed.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 16:57:00.365820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742749020.387683  760470 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742749020.394611  760470 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742749020.412938  760470 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742749020.412957  760470 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742749020.412959  760470 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742749020.412961  760470 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-23 16:57:00.419038: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "teacher_id = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(teacher_id)\n",
    "\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    teacher_id, \n",
    "    num_labels = num_labels,\n",
    "    id2label = id2label,\n",
    "    label2id = label2id,\n",
    ")\n",
    "\n",
    "teacher_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenize function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        # max_length=128,\n",
    "        padding=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef1ff9e9df848a38f78450700613566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/94889 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912225411c4744e0b00bd50a7d90956d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20333 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4c1730cd444de5947bdb33ccdcfa77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 94889\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 20333\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 20334\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list(task_to_keys[task_name])\n",
    "# column_dataset = [item for item in task_to_keys[task_name] if item is not None]\n",
    "# column_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 94889\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 20333\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 20334\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove column : 'premise', 'hypothesis', 'idx'\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(\"__index_level_0__\")\n",
    "#rename column : 'labels'\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([149])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0]['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] i don ' t care how threatened you feel, you can ' t go throwing respect for human rights and due process out the window and just blow a kid away to defend your shit. but this is america the free country founded on genocide and slavery where they hold people in prison camps for years without trial and property is worth more than life so [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_datasets['train'][0]['input_ids'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "#Data collator that will dynamically pad the inputs received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=1150)\n",
    "small_eval_dataset = tokenized_datasets[\"val\"].shuffle(seed=1150).select(range(1000))\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=1150).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    small_train_dataset, shuffle=True, batch_size=32, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(\n",
    "    small_test_dataset, batch_size=32, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(\n",
    "    small_eval_dataset, batch_size=32, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32]), torch.Size([32, 191]), torch.Size([32, 191]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "    \n",
    "batch['labels'].shape, batch['input_ids'].shape, batch['attention_mask'].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Design the model and losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Teacher Model & Student Model\n",
    "\n",
    "####  Architecture \n",
    "In the present work, the student - DistilBERT - has the same general architecture as BERT. \n",
    "- The `token-type embeddings` and the `pooler` are removed while `the number of layers` is reduced by a factor of 2. \n",
    "- Most of the operations used in the Transformer architecture `linear layer` and `layer normalisation` are highly optimized in modern linear algebra frameworks.\n",
    "- our investigations showed that variations on the last dimension of the tensor (hidden size dimension) have a smaller impact on computation efficiency (for a fixed parameters budget) than variations on other factors like the number of layers. \n",
    "- Thus we focus on reducing the number of layers.\n",
    "\n",
    "#### Initialize Student Model\n",
    "- To initialize a new model from an existing one, we need to access the weights of the old model (the teacher). \n",
    "- In order to get the weights, we first have to know how to access them. Weâ€™ll use BERT as our teacher model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"non-toxic\",\n",
       "    \"1\": \"toxic\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"non-toxic\": 0,\n",
       "    \"toxic\": 1\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.47.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model.config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "- The student model has the same configuration, except the number of layers is reduced by a factor of 2\n",
    "- The student layers are initilized by copying one out of two layers of the teacher, starting with layer 0.\n",
    "- The head of the teacher is also copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertConfig, BertModel, BertEncoder\n",
    "# Get teacher configuration as a dictionnary\n",
    "configuration = teacher_model.config.to_dict()\n",
    "# configuration\n",
    "configuration['num_hidden_layers'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half the number of hidden layer\n",
    "configuration['num_hidden_layers'] //= 2 \n",
    "# Convert the dictionnary to the student configuration\n",
    "configuration = BertConfig.from_dict(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"non-toxic\",\n",
       "    \"1\": \"toxic\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"non-toxic\": 0,\n",
       "    \"toxic\": 1\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.47.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = type(teacher_model)(configuration)\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recursively copies the weights of the (teacher) to the (student).\n",
    "- This function is meant to be first called on a BertFor... model, but is then called on every children of that model recursively.\n",
    "- The only part that's not fully copied is the encoder, of which only half is copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "\n",
    "def distill_bert_weights(teacher: Module, student: Module, even_or_odd: str) -> None:\n",
    "    \"\"\"\n",
    "    Recursively copies the weights from the teacher to the student.\n",
    "    This function is meant to be first called on a BertFor... model, but is then called\n",
    "    on every child module recursively.\n",
    "    The only part that's not fully copied is the encoder, of which only half the layers are copied.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determine the starting offset based on even or odd choice.\n",
    "    if even_or_odd == \"even\":\n",
    "        e = 1\n",
    "    elif even_or_odd == \"odd\":\n",
    "        e = 0\n",
    "    else:\n",
    "        raise ValueError(\"even_or_odd must be either 'even' or 'odd'\")\n",
    "        \n",
    "    # If the part is an entire BERT model or a BertFor... model, iterate through children\n",
    "    if isinstance(teacher, BertModel) or type(teacher).__name__.startswith('BertFor'):\n",
    "        for teacher_part, student_part in zip(teacher.children(), student.children()):\n",
    "            distill_bert_weights(teacher_part, student_part, even_or_odd)\n",
    "    # Else if the part is an encoder, copy one out of every layer\n",
    "    elif isinstance(teacher, BertEncoder):\n",
    "        teacher_encoding_layers = [layer for layer in next(teacher.children())]  # 12 layers\n",
    "        student_encoding_layers = [layer for layer in next(student.children())]  # 6 layers\n",
    "        for i in range(len(student_encoding_layers)):\n",
    "            teacher_index = 2 * i + e  # Calculate the teacher layer index based on even_or_odd\n",
    "            student_encoding_layers[i].load_state_dict(teacher_encoding_layers[teacher_index].state_dict())\n",
    "    # Else the part is a head or something else, copy the state_dict directly\n",
    "    else:\n",
    "        student.load_state_dict(teacher.state_dict())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_odd = distill_bert_weights(teacher=teacher_model, student=model, even_or_odd=\"odd\")\n",
    "model_even = distill_bert_weights(teacher=teacher_model, student=model, even_or_odd=\"even\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher parameters : 109483778\n",
      "Student parameters : 66956546\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('Teacher parameters :', count_parameters(teacher_model))\n",
    "print('Student parameters :', count_parameters(model_odd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.156590705154514"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model_odd)/count_parameters(teacher_model) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It has 40% less parameters than bert-base-uncased"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Loss function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax\n",
    "\n",
    "$$\n",
    "P_i(\\mathbf{z}_i, T) = \\frac{\\exp(\\mathbf{z}_i / T)}{\\sum_{q=0}^k \\exp(\\mathbf{z}_q / T)}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knowledge Distillation\n",
    "\n",
    "#### CE Loss\n",
    "$$\\mathcal{L}_\\text{CE} = -\\sum^N_{j=0}\\sum_{i=0}^k {y}_i^{(j)}\\log(P_i({v}_i^{(j)}, 1))$$\n",
    "\n",
    "#### KL Loss\n",
    "$$\\mathcal{L}_\\text{KD} = -\\sum^N_{j=0}\\sum_{i=0}^k P_i({z}_i^{(j)}, T) \\log (P_i({v}_i^{(j)}, T))$$\n",
    "\n",
    "#### Cosine Embedding Loss\n",
    "$$\\mathcal{L}_{\\text{cosine}}(x_1, x_2, y) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(1 - y_i \\cdot \\cos(\\theta_i)\\right)$$\n",
    "\n",
    "<!-- $$\\mathcal{L} = \\lambda \\mathcal{L}_\\text{KD} + (1-\\lambda)\\mathcal{L}_\\text{CE}$$\n",
    " -->\n",
    "\n",
    "#### Total Loss\n",
    "$$\\mathcal{L} = \\mathcal{L}_\\text{KD} + \\mathcal{L}_\\text{CE} + \\mathcal{L}_{\\text{cosine}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DistillKL(nn.Module):\n",
    "    \"\"\"\n",
    "    Distilling the Knowledge in a Neural Network\n",
    "    Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
    "    \"Hyperparameters\": temperature and alpha\n",
    "\n",
    "    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
    "    and student expects the input tensor to be log probabilities! \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DistillKL, self).__init__()\n",
    "\n",
    "    def forward(self, output_student, output_teacher, temperature=1):\n",
    "        '''\n",
    "        Note: the output_student and output_teacher are logits \n",
    "        '''\n",
    "        T = temperature #.cuda()\n",
    "        \n",
    "        KD_loss = nn.KLDivLoss(reduction='batchmean')(\n",
    "            F.log_softmax(output_student/T, dim=-1),\n",
    "            F.softmax(output_teacher/T, dim=-1)\n",
    "        ) * T * T\n",
    "        \n",
    "        return KD_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_div = DistillKL()\n",
    "criterion_cos = nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odds Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "lr = 5e-5\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First try Odd Model\n",
    "model = model_odd.to(device)\n",
    "teacher_model = teacher_model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 5\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "# Get the metric function\n",
    "task_name = None\n",
    "if task_name is not None:\n",
    "    metric = evaluate.load(\"glue\", task_name)\n",
    "else:\n",
    "    metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 109,778,690 || trainable%: 0.2686\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer, BertConfig, Trainer, TrainingArguments\n",
    "from transformers import AutoModel, AutoModelForCausalLM\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "from peft import (\n",
    "    get_peft_config, \n",
    "    get_peft_model, \n",
    "    PromptTuningInit, \n",
    "    PromptTuningConfig, \n",
    "    TaskType, \n",
    "    PeftType\n",
    "    )\n",
    "\n",
    "# Configure LoRA parameters.\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    inference_mode=False, \n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1\n",
    ")\n",
    "model = get_peft_model(teacher_model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "    # by preprocess_l\"ogits_for_metrics but we need to shift the labels\n",
    "    labels = labels[:, 1:].reshape(-1)\n",
    "    preds = preds[:, :-1].reshape(-1)\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1100884921a24ed6bd718888f8e80930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 1: Train loss 0.2336:\n",
      "  - Loss_cls: 0.7009\n",
      "  - Loss_div: 0.0000\n",
      "  - Loss_cos: 0.0000\n",
      "Epoch at 1: Test Acc 0.4670\n",
      "Epoch at 2: Train loss 0.2336:\n",
      "  - Loss_cls: 0.7009\n",
      "  - Loss_div: 0.0000\n",
      "  - Loss_cos: 0.0000\n",
      "Epoch at 2: Test Acc 0.4670\n",
      "Epoch at 3: Train loss 0.2336:\n",
      "  - Loss_cls: 0.7009\n",
      "  - Loss_div: 0.0000\n",
      "  - Loss_cos: 0.0000\n",
      "Epoch at 3: Test Acc 0.4670\n",
      "Epoch at 4: Train loss 0.2336:\n",
      "  - Loss_cls: 0.7009\n",
      "  - Loss_div: 0.0000\n",
      "  - Loss_cos: 0.0000\n",
      "Epoch at 4: Test Acc 0.4670\n",
      "Epoch at 5: Train loss 0.2336:\n",
      "  - Loss_cls: 0.7009\n",
      "  - Loss_div: 0.0000\n",
      "  - Loss_cos: 0.0000\n",
      "Epoch at 5: Test Acc 0.4670\n",
      "Avg Metric 0.46699999999999997\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "eval_metrics = 0\n",
    "\n",
    "# Lists to store losses for each epoch\n",
    "train_losses = []\n",
    "train_losses_cls = []\n",
    "train_losses_div = []\n",
    "train_losses_cos = []\n",
    "eval_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    teacher_model.eval()\n",
    "    train_loss = 0\n",
    "    train_loss_cls = 0\n",
    "    train_loss_div = 0\n",
    "    train_loss_cos = 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        # compute student output\n",
    "        outputs = model(**batch) \n",
    "        # compute teacher output\n",
    "        with torch.no_grad():\n",
    "            output_teacher = teacher_model(**batch)\n",
    "\n",
    "        # assert size\n",
    "        assert outputs.logits.size() == output_teacher.logits.size()\n",
    "        \n",
    "        # cls loss \n",
    "        loss_cls  = outputs.loss\n",
    "        train_loss_cls += loss_cls.item()\n",
    "        # distillation loss\n",
    "        loss_div = criterion_div(outputs.logits, output_teacher.logits)\n",
    "        train_loss_div += loss_div.item()\n",
    "        # cosine loss\n",
    "        loss_cos = criterion_cos(output_teacher.logits, outputs.logits, torch.ones(output_teacher.logits.size()[0]).to(device))\n",
    "        train_loss_cos += loss_cos.item()\n",
    "        \n",
    "        # Average the loss and return it\n",
    "        loss = (loss_cls + loss_div + loss_cos) / 3\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        # accelerator.backward(loss)\n",
    "        # Step with optimizer\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    train_losses.append(train_loss / len(train_dataloader))\n",
    "    train_losses_cls.append(train_loss_cls / len(train_dataloader))\n",
    "    train_losses_div.append(train_loss_div / len(train_dataloader))\n",
    "    train_losses_cos.append(train_loss_cos / len(train_dataloader))\n",
    "\n",
    "    print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n",
    "    print(f'  - Loss_cls: {train_loss_cls/len(train_dataloader):.4f}')\n",
    "    print(f'  - Loss_div: {train_loss_div/len(train_dataloader):.4f}')\n",
    "    print(f'  - Loss_cos: {train_loss_cos/len(train_dataloader):.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            \n",
    "        loss_cls = outputs.loss\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "        eval_loss += loss_cls.item()\n",
    "        # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n",
    "        metric.add_batch(\n",
    "            predictions=predictions, \n",
    "            references=batch[\"labels\"])\n",
    "        \n",
    "    eval_metric = metric.compute()\n",
    "    eval_metrics += eval_metric['accuracy'] \n",
    "    eval_losses.append(eval_loss / len(eval_dataloader))  # Save the evaluation loss for plotting\n",
    "    \n",
    "    print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n",
    "    \n",
    "print('Avg Metric', eval_metrics/num_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting\n",
    "epochs_list = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs_list, train_losses, label='Total Train Loss')\n",
    "plt.plot(epochs_list, train_losses_cls, label='Train Loss_cls')\n",
    "plt.plot(epochs_list, train_losses_div, label='Train Loss_div')\n",
    "plt.plot(epochs_list, train_losses_cos, label='Train Loss_cos')\n",
    "plt.plot(epochs_list, eval_losses, label='Validation Loss')\n",
    "\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/LoRa/tokenizer_config.json',\n",
       " 'models/LoRa/special_tokens_map.json',\n",
       " 'models/LoRa/vocab.txt',\n",
       " 'models/LoRa/added_tokens.json',\n",
       " 'models/LoRa/tokenizer.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('models/LoRa/')\n",
    "tokenizer.save_pretrained('models/LoRa/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
